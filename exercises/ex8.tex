\documentclass[a4paper,11pt]{article}

\usepackage[pdftex]{graphicx}
%\usepackage{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[T1,mtbold,lucidacal,mtplusscr,subscriptcorrection]{mathtime}
\usepackage{times}
\usepackage{amsmath,amssymb}
\usepackage[hyphens]{url}
\usepackage{enumerate}
\usepackage{parskip}
\usepackage[colorlinks,urlcolor=black]{hyperref}

% if not draft, smaller printable area makes the paper more readable
\topmargin -4mm
\oddsidemargin 0mm
\textheight 225mm
\textwidth 150mm

%\parskip=\baselineskip

\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\Sd}{Sd}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Beta}{Beta}
\DeclareMathOperator{\Poisson}{Poisson}
\DeclareMathOperator{\betacdf}{betacdf}
\DeclareMathOperator{\Invchi2}{Inv-\chi^2}
\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\N}{N}
\DeclareMathOperator{\U}{U}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\trace}{trace}

\pagestyle{empty}

\begin{document}
\thispagestyle{empty}

\section*{Bayesian data analysis -- exercise 8}

This assignment is related to Chapter 7.

The maximum amount of points from this assignment is 6. In addition to the correctness of the answers, the overall quality and clearness of the report is evaluated.

Report all results to a single, {\bf anonymous} *.pdf -file and return it to \href{peergrade.io}{peergrade.io}. Include also source code to the report (either as an attachment or as a part of the answer). By anonymity it is meant that the report should not contain your name or student number.

\vspace{1cm}







\subsection*{Model assessment: LOO-CV for factory data with Stan (6p)}

Use leave-one-out cross validation (LOO-CV) to assess the predictive performance of the pooled, separate and hierarchical Gaussian models for the factory dataset (see the second exercise in Assignment 7).
Use Stan for fitting the models, and the provided PSIS-LOO (Pareto smoothed importance sampling LOO) code for computing the approximate LOO-CV given the posterior samples provided by Stan. Your results should include:
\begin{itemize}
	\item PSIS-LOO values, the effective number of parameters $p_\text{eff}$, and the $k$-values for each of the three models
	\item an assessment of how reliable the PSIS-LOO estimates are for the three models based on the $k$-values
	\item an assessment of whether there are differences between the models, and if so, which model should be selected according to PSIS-LOO
\end{itemize}
%Remember also to comment on the results.


Hints and further advice:
\begin{itemize}
%\item The code for computing the PSIS-LOO can be found at \url{https://github.com/avehtari/PSIS}
%\item In the hierarchical model, use the same measurement standard deviation $\sigma$ for all the groups, similarly as in the book (Sec.~11.6) and in Assignment~6.
\item Fit the models with Stan as instructed in Assignment~6.
%\item In all the three models, use uniform priors for all the parameters.
%\item In the hierarchical model, use the same measurement deviation $\sigma$ for all the machines. This is reasonable, since there are so few measurements per machine, so learning the deviations separately for each machine is difficult. If you want, you can also compute the PSIS-LOO value for the hierarchical model with different $\sigma_j$ for each machine and see the effect in the estimated predictive performance (this is not, however, required for full points). For the separate model, you should still use different $\sigma_j$ for each machine.
\item In R, you can use the function {\tt loo} in package {\tt loo}. You can install the package with command {\tt install.packages(loo)}. The Python and Matlab implementations are available at \url{https://github.com/avehtari/PSIS}. For both languages, the function that you will need is {\tt psisloo}.
\item In order to use the {\tt loo} or {\tt psisloo} functions, you need to compute the log-likelihood values of each observation for every posterior draw (i.e. an $S$-by-$n$ matrix, where $S$ is the number of posterior draws and $n=30$ is the total number of observations). This can be done in the {\tt generated quantities} block in the Stan code; for a demonstration, see the Gaussian linear model in the R/Python/Matlab Stan examples (file {\tt lin.stan} in R and Python demos).
\item It will be convenient to visualize the $k$-values for each model, so that you can easily see how many of these values fall in the range $k > 0.7$ to assess the reliability of the PSIS-LOO estimate for each model. You can read more about the theoretical guarantees for the accuracy of the estimate depending on $k$ from the original article (see the link below), but regarding this assignment, it suffices to understand that if all the $k$-values are $k \lesssim 0.7$, the PSIS-LOO estimate can be considered to be reliable, otherwise there is a concern that it may be biased (too optimistic, overestimating the predictive accuracy of the model).
\item The estimated effective number of parameters in the model can be computed from equation~(7.15) in the book, where $\text{lppd}_\text{loo-cv}$ is the PSIS-LOO value (sum of the LOO log densities) and lppd is given by equation~(7.5) in the book.
\item PSIS-LOO is a recently developed method for approximating the exact LOO and is thus not in BDA3. For more information, see the lecture slides and the original paper \url{https://arxiv.org/pdf/1507.04544}.
\end{itemize}













\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:























